import os
import openai
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from dotenv import load_dotenv

# --------------------
# ğŸ”§ ç¯å¢ƒé…ç½®
# --------------------
load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
openai.api_base = os.getenv("OPENAI_BASE_URL")

DB_USERNAME = os.getenv("DB_USERNAME")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST", "127.0.0.1")
DB_PORT = int(os.getenv("DB_PORT", 3306))
TARGET_DB = os.getenv("TARGET_DB")

DATABASE_URL = f"mysql+pymysql://{DB_USERNAME}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{TARGET_DB}"

# åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
engine = create_engine(DATABASE_URL, echo=False)
SessionLocal = sessionmaker(bind=engine)

# ----------------------
# ğŸ“˜ Schema-aware Prompt
# ----------------------
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ª SQL ç”Ÿæˆå™¨ï¼Œè¯·æ ¹æ®è‡ªç„¶è¯­è¨€è¯·æ±‚ç”Ÿæˆ MySQL æŸ¥è¯¢è¯­å¥ï¼ŒæŸ¥è¯¢çš„æ•°æ®ç»“æ„å¦‚ä¸‹ï¼š

- model(model_id, model_name, param_num, media_type, arch_name)
- model_tasks(model_id, task_name)
- cnn(model_id, module_num)
- transformer(model_id, decoder_num, attn_size, up_size, down_size, embed_size)
- rnn(model_id, criteria, batch_size, input_size)
- dataset(ds_id, ds_name, ds_size, media, task)
- ds_col(ds_id, col_name, col_datatype)
- user(user_id, user_name, affiliate)
- affil(affil_id, affil_name)
- user_affil(user_id, affil_id)
- model_author(model_id, user_id)
- model_dataset(model_id, dataset_id)
- user_ds(user_id, ds_id)

åªè¿”å› SQL æŸ¥è¯¢è¯­å¥ï¼Œä¸è¦æ·»åŠ å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚"""

# ----------------------
# ğŸ” ç”Ÿæˆ SQL
# ----------------------
def natural_language_to_sql(nl_input: str) -> str:
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": nl_input}
        ],
        temperature=0,
    )
    return response.choices[0].message["content"].strip("` \n")

# ----------------------
# âŒ é”™è¯¯è‡ªåŠ¨ä¿®å¤
# ----------------------
def fix_sql_with_error(nl_input: str, original_sql: str, error_msg: str) -> str:
    fix_prompt = f"""
åŸå§‹è‡ªç„¶è¯­è¨€è¯·æ±‚æ˜¯ï¼š
{nl_input}

ç”Ÿæˆçš„ SQL æ˜¯ï¼š
{original_sql}

æ‰§è¡Œæ—¶å‡ºç°äº†é”™è¯¯ï¼š
{error_msg}

è¯·ä¿®å¤è¿™ä¸ª SQL æŸ¥è¯¢ï¼Œè¿”å›æ­£ç¡®è¯­æ³•çš„ SQL æŸ¥è¯¢è¯­å¥ã€‚
"""
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": fix_prompt}
        ],
        temperature=0,
    )
    return response.choices[0].message["content"].strip("` \n")

# ----------------------
# ğŸ§ª æ‰§è¡Œ SQL
# ----------------------
def execute_sql(sql: str):
    session = SessionLocal()
    try:
        result = session.execute(text(sql))
        rows = result.fetchall()
        columns = result.keys()
        return [dict(zip(columns, row)) for row in rows], None
    except Exception as e:
        return None, str(e)
    finally:
        session.close()

# ----------------------
# ğŸš€ ä¸»é€»è¾‘
# ----------------------
def query_agent(nl_input: str):
    print("ğŸ¯ ç”¨æˆ·è¾“å…¥ï¼š", nl_input)

    # ç¬¬ä¸€æ¬¡ç”Ÿæˆ SQL
    sql = natural_language_to_sql(nl_input)
    print("\nğŸ§  GPTç”Ÿæˆçš„SQLï¼š", sql)

    result, error = execute_sql(sql)

    # å¦‚æœå‡ºé”™ï¼Œå°è¯•ä¿®å¤
    if error:
        print("\nâš ï¸ æ‰§è¡Œå‡ºé”™ï¼Œå°è¯•è‡ªåŠ¨ä¿®å¤ä¸­...")
        fixed_sql = fix_sql_with_error(nl_input, sql, error)
        print("\nğŸ” ä¿®å¤åçš„SQLï¼š", fixed_sql)
        result, error = execute_sql(fixed_sql)

        if error:
            print("\nâŒ ä¿®å¤ä»å¤±è´¥ï¼š", error)
        else:
            print("\nâœ… ä¿®å¤æˆåŠŸï¼Œç»“æœå¦‚ä¸‹ï¼š")
            print(result)
    else:
        print("\nâœ… æ‰§è¡ŒæˆåŠŸï¼Œç»“æœå¦‚ä¸‹ï¼š")
        print(result)

# ----------------------
# ğŸƒ å…¥å£
# ----------------------
if __name__ == "__main__":
    nl_input = input("ğŸ“ è¯·è¾“å…¥ä½ çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼š\n> ")
    query_agent(nl_input)
